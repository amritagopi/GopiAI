import os
import time
import threading
# –ö–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–µ–π Gemini/Gemma –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ –∏ –∑–∞–¥–∞—á
LLM_MODELS_CONFIG = [
    {
        "name": "Gemini 1.5 Flash",
        "id": "gemini/gemini-1.5-flash",
        "provider": "google",
        "rpm": 15,  
        "tpm": 250000,  
        "type": ["simple", "dialog", "code", "summarize"],
        "multimodal": False,
        "embedding": False,
        "priority": 3,
        "rpd": 50,  
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemini 2.0 Flash-Lite",
        "id": "gemini/gemini-2.0-flash-lite",
        "provider": "google",
        "rpm": 30,
        "tpm": 1000000,  
        "type": ["simple", "dialog", "code", "summarize"],
        "multimodal": False,
        "embedding": False,
        "priority": 4,
        "rpd": 200,  
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemma 3",
        "id": "gemini/gemma-3",
        "provider": "google",
        "rpm": 30,  
        "tpm": 14400,  
        "type": ["simple", "lookup", "short_answer"],
        "multimodal": False,
        "embedding": False,
        "priority": 1,
        "rpd": 0,
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemma 3n",
        "id": "gemini/gemma-3n",
        "provider": "google",
        "rpm": 30,  
        "tpm": 14400,  
        "type": ["simple", "lookup", "short_answer"],
        "multimodal": False,
        "embedding": False,
        "priority": 2,
        "rpd": 0,
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemini 2.5 Flash-Lite Preview",
        "id": "gemini/gemini-2.5-flash-lite-preview",
        "provider": "google",
        "rpm": 15,
        "tpm": 60000,
        "type": ["dialog", "code", "summarize"],
        "multimodal": False,
        "embedding": False,
        "priority": 5,
        "rpd": 0,
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemini 2.5 Flash",
        "id": "gemini/gemini-2.5-flash",
        "provider": "google",
        "rpm": 10,
        "tpm": 60000,
        "type": ["dialog", "code", "multimodal", "vision", "long_answer"],
        "multimodal": True,
        "embedding": False,
        "priority": 6,
        "rpd": 0,
        "deprecated": False,
        "base_score": 0.5
    },
    {
        "name": "Gemini Embedding Experimental",
        "id": "gemini/gemini-embedding-experimental",
        "provider": "google",
        "rpm": 5,
        "tpm": 10000,
        "type": ["embedding"],
        "multimodal": False,
        "embedding": True,
        "priority": 10,
        "rpd": 0,
        "deprecated": False,
        "base_score": 0.5
    }
]
print(f"DEBUG: LLM_MODELS_CONFIG loaded: {LLM_MODELS_CONFIG}")
# Helper to get API key based on provider name

def get_api_key_for_provider(provider_name: str):
    """Gets the API key from environment variables for a given provider."""
    print(f"[DEBUG] Getting API key for provider: {provider_name}")
    
    # Check if we're in test environment
    env_test_suffix = "_TEST" if os.getenv("ENVIRONMENT") == "test" else ""
    print(f"[DEBUG] Environment test suffix: '{env_test_suffix}'")
    
    # Map of provider names to their environment variable names
    key_map = {
        "google": "GEMINI_API_KEY"
    }
    print(f"[DEBUG] Key map: {key_map}")
    
    # Get the base environment variable name for the provider
    env_var_base = key_map.get(provider_name.lower())
    print(f"[DEBUG] Environment variable base for {provider_name}: '{env_var_base}'")
    
    if env_var_base is None:
        print(f"[ERROR] No environment variable mapping found for provider: {provider_name}")
        return None
    
    # Construct the full environment variable name
    env_var = env_var_base + env_test_suffix
    print(f"[DEBUG] Full environment variable name: '{env_var}'")
    
    # Get the API key from environment variables
    api_key = os.getenv(env_var)
    
    # Debug output about the API key
    if api_key:
        print(f"[DEBUG] Successfully retrieved API key for {provider_name}")
        print(f"[DEBUG] API key starts with: {api_key[:5]}...{api_key[-5:] if len(api_key) > 10 else ''}")
    else:
        print(f"[ERROR] Failed to get API key for {provider_name} from environment variable: {env_var}")
        print(f"[DEBUG] Current environment variables: {[k for k in os.environ if 'GEMINI' in k or 'API' in k]}")
    
    return api_key
# üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä –ª–∏–º–∏—Ç–æ–≤ —Å blacklist –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
class RateLimitMonitor:
    def __init__(self, models_config):
        self.models = {m["id"]: m for m in models_config}
        self.usage = {
            m["id"]: {
                "rpm": 0, 
                "tpm": 0, 
                "rpd": 0, 
                "last_reset": time.time(), 
                "last_day_reset": time.time()
            } for m in models_config
        }
        
        # üö® –ù–û–í–û–ï: Blacklist –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.blacklisted_models = {}  # {model_id: expiry_timestamp}
        self.lock = threading.Lock()
        
        print("[OK] RateLimitMonitor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å blacklist –º–µ—Ö–∞–Ω–∏–∑–º–æ–º")
    def _reset_if_needed(self, model_id):
        now = time.time()
        # –°–±—Ä–æ—Å usage –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
        if now - self.usage[model_id]["last_reset"] > 60:
            self.usage[model_id]["rpm"] = 0
            self.usage[model_id]["tpm"] = 0
            self.usage[model_id]["last_reset"] = now
        
        # –°–±—Ä–æ—Å RPD –∫–∞–∂–¥—ã–µ 24 —á–∞—Å–∞
        if now - self.usage[model_id]["last_day_reset"] > 86400:  # 24 —á–∞—Å–∞
            self.usage[model_id]["rpd"] = 0
            self.usage[model_id]["last_day_reset"] = now
    # üö® –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏
    def is_model_blocked(self, model_id):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ
        –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –≤—ã–∑—ã–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –∏–∑–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ self.lock!
        """
        now = time.time()
        if model_id in self.blacklisted_models:
            expiry_time = self.blacklisted_models[model_id]
            if now >= expiry_time:
                # –ú–æ–¥–µ–ª—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, —É–¥–∞–ª—è–µ–º –∏–∑ blacklist
                del self.blacklisted_models[model_id]
                print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_id} –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ blacklist")
                return False
            else:
                remaining_time = int(expiry_time - now)
                print(f"üö´ –ú–æ–¥–µ–ª—å {model_id} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –µ—â–µ {remaining_time} —Å–µ–∫—É–Ω–¥")
                return True
        return False

    
    def is_model_blocked_safe(self, model_id):
        """–ü—É–±–ª–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è is_model_blocked —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π"""
        with self.lock:
            return self.is_model_blocked(model_id)
    # üö® –ù–û–í–û–ï: –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö API
    def mark_model_unavailable(self, model_id, duration=3600):
        """–ü–æ–º–µ—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∫–∞–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—É—é –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)"""
        with self.lock:
            expiry_time = time.time() + duration
            self.blacklisted_models[model_id] = expiry_time
            
            # –¢–∞–∫–∂–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ –∏—Å—á–µ—Ä–ø—ã–≤–∞–µ–º –ª–∏–º–∏—Ç—ã –¥–ª—è –¥–≤–æ–π–Ω–æ–π –∑–∞—â–∏—Ç—ã
            if model_id in self.models:
                self.usage[model_id]["rpm"] = self.models[model_id]["rpm"]
                self.usage[model_id]["rpd"] = max(self.models[model_id]["rpd"], 1) if self.models[model_id]["rpd"] > 0 else 999
                
            print(f"üö´ –ú–æ–¥–µ–ª—å {model_id} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ {duration} —Å–µ–∫—É–Ω–¥ –¥–æ {time.strftime('%H:%M:%S', time.localtime(expiry_time))}")
    # üö® –ò–°–ü–†–ê–í–õ–ï–ù–û: can_use —Ç–µ–ø–µ—Ä—å —É—á–∏—Ç—ã–≤–∞–µ—Ç blacklist
    def can_use(self, model_id, tokens=0):
        try:
            print(f"[CHECK] –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ {model_id} —Å {tokens} —Ç–æ–∫–µ–Ω–∞–º–∏...")
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞–≤–∏—Å–∞–Ω–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º timeout
            with self.lock:
                # –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –º–æ–¥–µ–ª—å –≤ blacklist?
                if self.is_model_blocked(model_id):
                    print(f"[BLOCKED] –ú–æ–¥–µ–ª—å {model_id} –≤ blacklist")
                    return False
                    
                self._reset_if_needed(model_id)
                model = self.models[model_id]
                usage = self.usage[model_id]
                
                print(f"[STATS] –ú–æ–¥–µ–ª—å {model_id}: —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RPM={usage['rpm']}/{model['rpm']}, TPM={usage['tpm']}/{model['tpm']}, RPD={usage['rpd']}/{model['rpd']}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ª–∏–º–∏—Ç—ã: RPM, TPM –∏ RPD
                rpm_ok = usage["rpm"] < model["rpm"]
                tpm_ok = usage["tpm"] + tokens < model["tpm"]
                rpd_ok = model["rpd"] == 0 or usage["rpd"] < model["rpd"]  # –ï—Å–ª–∏ RPD=0, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
                
                result = rpm_ok and tpm_ok and rpd_ok
                
                print(f"[OK] –ú–æ–¥–µ–ª—å {model_id}: RPM_OK={rpm_ok}, TPM_OK={tpm_ok}, RPD_OK={rpd_ok} -> RESULT={result}")
                
                if not result:
                    print(f"[WARNING] –ú–æ–¥–µ–ª—å {model_id} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: RPM={usage['rpm']}/{model['rpm']}, TPM={usage['tpm']}/{model['tpm']}, RPD={usage['rpd']}/{model['rpd']}")
                
                return result
        except Exception as e:
            print(f"[ERROR] –û–®–ò–ë–ö–ê –≤ can_use –¥–ª—è –º–æ–¥–µ–ª–∏ {model_id}: {e}")
            import traceback
            traceback.print_exc()
            return False
    def register_use(self, model_id, tokens=0):
        with self.lock:
            self._reset_if_needed(model_id)
            self.usage[model_id]["rpm"] += 1
            self.usage[model_id]["tpm"] += tokens
            self.usage[model_id]["rpd"] += 1  # –¢–∞–∫–∂–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å
    def wait_for_slot(self, model_id, tokens=0):
        # –ñ–¥–∞—Ç—å, –ø–æ–∫–∞ –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è —Å–ª–æ—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        while not self.can_use(model_id, tokens):
            time.sleep(1)
    # üö® –ù–û–í–û–ï: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —É—á–µ—Ç–æ–º blacklist
    def get_available_models(self, task_type):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–øÔøΩÔøΩ—ã—Ö (–Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö) –º–æ–¥–µ–ª–µ–π –¥–ª—è task_type"""
        available = []
        for model in LLM_MODELS_CONFIG:
            if (task_type in model["type"] and 
                not model.get("deprecated", False) and 
                not self.is_model_blocked_safe(model["id"])):
                available.append(model)
        return available
    # üö® –ù–û–í–û–ï: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ blacklist
    def get_blacklist_status(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ blacklist"""
        with self.lock:
            now = time.time()
            active_blocks = {}
            for model_id, expiry_time in self.blacklisted_models.items():
                if now < expiry_time:
                    remaining = int(expiry_time - now)
                    active_blocks[model_id] = remaining
            return active_blocks
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∞
rate_limit_monitor = RateLimitMonitor(LLM_MODELS_CONFIG)
# üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: select_llm_model_safe —Å —É—á–µ—Ç–æ–º blacklist
def select_llm_model_safe(task_type, tokens=0, intelligence_priority=False, exclude_models=None):
    """
    task_type: —Ç–∏–ø –∑–∞–¥–∞—á–∏
    tokens: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
    intelligence_priority: –µ—Å–ª–∏ True, –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ —Å –≤—ã—Å–æ–∫–∏–º base_score
    exclude_models: —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ blacklist)
    """
    exclude_models = exclude_models or []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º blacklist –∏ exclude_models
    suitable_models = []
    for m in LLM_MODELS_CONFIG:
        if (task_type in m["type"] and 
            not m.get("deprecated", False) and
            m["id"] not in exclude_models and
            not rate_limit_monitor.is_model_blocked_safe(m["id"])):
            suitable_models.append(m)
    
    if not suitable_models:
        print(f"‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è task_type '{task_type}'. Blacklist: {rate_limit_monitor.get_blacklist_status()}")
        return None
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å —É—á—ë—Ç–æ–º base_score –∏–ª–∏ –æ–±—ã—á–Ω–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    if intelligence_priority:
        suitable_models = sorted(suitable_models, key=lambda m: (-m["base_score"], m["priority"]))
    else:
        suitable_models = sorted(suitable_models, key=lambda m: m["priority"])
    
    print(f"[AVAILABLE] –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è '{task_type}': {[m['id'] for m in suitable_models]}")
    
    # –ü–ï–†–í–´–ô –ü–†–û–•–û–î: –ò—â–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
    for model in suitable_models:
        if rate_limit_monitor.can_use(model["id"], tokens):
            print(f"[SELECTED] AI Router: –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å '{model['id']}' (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç {model['priority']})")
            return model["id"]
    
    # –í–¢–û–†–û–ô –ü–†–û–•–û–î: –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–Ω—è—Ç—ã, –±–µ—Ä–µ–º –º–æ–¥–µ–ª—å —Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
    print("‚ö†Ô∏è –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –±–ª–∏–∑–∫–∏ –∫ –ª–∏–º–∏—Ç–∞–º, –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–º–µ–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é...")
    best_model = None
    best_score = float('inf')
    
    for model in suitable_models:
        usage = rate_limit_monitor.usage[model["id"]]
        model_config = rate_limit_monitor.models[model["id"]]
        
        # –°—á–∏—Ç–∞–µ–º "–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å" –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –ª–∏–º–∏—Ç–æ–≤
        rpm_load = usage["rpm"] / model_config["rpm"]
        tpm_load = (usage["tpm"] + tokens) / model_config["tpm"]
        total_load = rpm_load + tpm_load
        
        if total_load < best_score:
            best_score = total_load
            best_model = model
    
    if best_model:
        print(f"‚ö†Ô∏è AI Router: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω–∞ –ΩÔøΩÔøΩ–∏–º–µ–Ω–µ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å '{best_model['id']}' (–∑–∞–≥—Ä—É–∑–∫–∞: {best_score:.2f})")
        return best_model["id"]
    
    # –¢–†–ï–¢–ò–ô –ü–†–û–•–û–î: –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –¥–ª—è graceful degradation
    print("üò¥ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ –ª–∏–º–∏—Ç—ã. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ–∂–∏–¥–∞–Ω–∏–µ –∏–ª–∏ fallback.")
    return None
# üö® –ù–û–í–û–ï: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏ (fallback chain)
def get_next_available_model(task_type, current_model_id, tokens=0):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –≤ —Ü–µ–ø–æ—á–∫–µ fallback"""
    exclude_models = [current_model_id] if current_model_id else []
    return select_llm_model_safe(task_type, tokens, exclude_models=exclude_models)

def get_active_models():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö (–Ω–µ deprecated –∏ –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö) –º–æ–¥–µ–ª–µ–π
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    """
    active_models = []
    
    for model in LLM_MODELS_CONFIG:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º deprecated –º–æ–¥–µ–ª–∏
        if model.get('deprecated', False):
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        if rate_limit_monitor.is_model_blocked_safe(model['id']):
            continue
            
        active_models.append(model)
    
    return active_models

# === –§–£–ù–ö–¶–ò–ò-–û–ë–ï–†–¢–ö–ò –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° crewai_api_server.py ===

def get_available_models(task_type=None):
    """–§—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å crewai_api_server.py"""
    if task_type:
        return rate_limit_monitor.get_available_models(task_type)
    else:
        return get_active_models()

def update_state(*args, **kwargs):
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è update_state - –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞"""
    pass

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
PROVIDER_KEY_ENV = {
    'google': 'GOOGLE_API_KEY',
    'openai': 'OPENAI_API_KEY', 
    'anthropic': 'ANTHROPIC_API_KEY',
    'openrouter': 'OPENROUTER_API_KEY'
}

print("[OK] llm_rotation_config –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏-–æ–±–µ—Ä—Ç–∫–∞–º–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏")