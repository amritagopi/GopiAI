Okay, зайка, держись. Это реально тотальный пиздец, но это **хороший, диагностический пиздец**. Теперь у нас есть всё, чтобы поставить диагноз и составить четкий план лечения. Выдыхай, заваривай кофе, сейчас всё разложим.

Я проанализировала чат, оба лога и советы. Ты не поверишь, но все эти разрозненные симптомы — от `lss*([^n]*)` до падений и пустых ответов — сводятся к **двум корневым проблемам** в твоём бэкенде.

---

### Диагноз: Что именно сломано и почему

#### **Проблема №1: Кривой `try-except` и неправильный `raise` (90% всех бед).**

Это самая главная ошибка, которая маскирует все остальные. Смотри на этот трейсбек из `crewai_api_server_debug.log`:

```python
# 1. litellm правильно кидает ошибку RateLimitError от OpenRouter
litellm.exceptions.RateLimitError: litellm.RateLimitError: ...

# 2. Твой код в smart_delegator.py ловит эту ошибку...
#    ...и пытается кинуть СВОЮ собственную ошибку RateLimitError.
raise RateLimitError(f"�������� ����� �������� ��� ������ {model_id}. ���������� �����.")

# 3. И вот тут всё падает с новой, другой ошибкой:
TypeError: RateLimitError.__init__() missing 2 required positional arguments: 'llm_provider' and 'model'
```

**Что это значит на человеческом:**
Твой код пытается быть умным: он ловит ошибку от `litellm`, но вместо того, чтобы просто обработать её, он пытается создать *свой собственный* объект `RateLimitError` от `litellm`. Но он делает это неправильно! Конструктор этого класса ожидает параметры `llm_provider` и `model`, а ты ему даешь просто строку. В итоге, у тебя происходит **ошибка внутри обработчика ошибок**.

**Последствия:**
*   **Пустые ответы:** Вместо того чтобы вернуть в UI понятное сообщение "Сорян, лимит запросов", твой бэкенд падает с `TypeError`, не успев ничего сформировать, и возвращает пустоту. Отсюда все эти "Ошибка: LLM вернул пустой ответ".
*   **Сбитый с толку LLM:** Модель не получает обратной связи о том, что инструмент не сработал из-за лимита, и в следующем сообщении продолжает вести себя как ни в чем не бывало.

#### **Проблема №2: Наследие "парсерного" подхода к инструментам (остальные 10%).**

Как мы и думали, твоя система не использует современный `tool_calls`. Она пытается выковырять команды из текста.

*   **Логи это подтверждают:** `[PARSER] Найдена текстовая команда: lss*([^n]*) ...` и `[EXECUTOR] Команда не разрешена: lss*([^n]*)`.
*   **Чат это подтверждает:** Модель генерирует текст `ls -la GOPI_AI_MODULES`, а в ответ получает `Команда "ls" не разрешена для выполнения`. Это значит, что твой парсер, даже если бы не был сломан, наткнулся бы на Whitelist команд, в котором нет `ls`.

---

### План по спасению проекта (без хуйни, по шагам)

Забудь пока про UI и примеры. Сосредоточься на бэкенде (`GopiAI-CrewAI`). Чиним его, и 95% проблем уйдут.

#### **Часть I: Хирургическое Вмешательство (Бэкенд)**

**Задача: Вылечить обработку ошибок и внедрить настоящие инструменты.**

1.  **[Срочно!] Закомментируй Кривой `raise`:**
    *   **Где:** `C:\Users\crazy\GOPI_AI_MODULES\GopiAI-CrewAI\tools\gopiai_integration\smart_delegator.py`, строка `1012`.
    *   **Что делать:** Найди эту строку и ЗАКОММЕНТИРУЙ ЕЕ. Вместо нее просто пробрасывай ошибку дальше.
    *   **Было:**
        ```python
        except RateLimitError as e:
            # ...логирование...
            raise RateLimitError(f"Достигнут лимит запросов для модели {model_id}. Попробуйте позже.") # <-- ЭТА СТРОКА УБИВАЕТ ВСЁ
        ```
    *   **Стало (простой вариант):**
        ```python
        except RateLimitError as e:
            logging.error(f"Rate limit error from OpenRouter for model {model_id}: {e}")
            # Просто пробрасываем оригинальную ошибку, чтобы ее поймал внешний обработчик
            raise e
        ```
    *   **Что это даст:** Ты перестанешь получать `TypeError`. Вместо этого в логах будет четкая ошибка `RateLimitError`, и ты сможешь ее нормально обработать и вернуть в UI осмысленное сообщение.

2.  **[Важно!] Переход на Нативный Tool Calling (как мы обсуждали):**
    *   **Шаг 2.1: Создай `tool_schema.py`:** В папке `gopiai_integration` создай файл `tool_schema.py` и опиши там свои инструменты в формате OpenAI JSON. Начни с одного, для теста.
        ```python
        # gopiai_integration/tool_schema.py
        def get_tools():
            return [{
                "type": "function",
                "function": {
                    "name": "list_files",
                    "description": "Получить список файлов в директории.",
                    "parameters": {
                        "type": "object",
                        "properties": {"path": {"type": "string", "description": "Путь к папке"}},
                        "required": ["path"],
                    },
                },
            }]
        ```
    *   **Шаг 2.2: Модифицируй `_call_llm_with_tools`:** У тебя в логах уже есть эта функция. Переделай ее под двухэтапный вызов, как я описывала ранее. Убери свой `[PARSER]` и `lss...` из логики.
    *   **Шаг 2.3: Адаптируй `CommandExecutor`:** Он должен принимать имя функции (`list_files`) и словарь аргументов (`{'path': 'GOPI_AI_MODULES'}`), а не пытаться парсить строку.
    *   **Шаг 2.4: Настрой Whitelist:** В `CommandExecutor`'е в списке разрешенных команд должны быть **имена функций** из твоей схемы (`list_files`), а не команды ОС (`ls`, `dir`).

#### **Часть II: Косметический Ремонт (UI и Прочее)**

**Задача: Починить то, что сломалось на клиенте, и прибраться.**

1.  **[UI] Краш `rich_text_notebook_widget.py`:**
    *   **Проблема:** Ты пытаешься создать новую вкладку, но не сохраняешь на нее ссылку. Python's Garbage Collector ее съедает, а Qt потом пытается к ней обратиться и падает.
    *   **Решение:** В методе, где ты создаешь новую вкладку, добавь ее в список, который является атрибутом класса. Например: `self.open_tabs.append(new_tab_widget)`.

2.  **[UI] Плавающий Терминал:**
    *   **Проблема:** При создании `TerminalWidget` ты не указываешь родителя.
    *   **Решение:** Найди `TerminalWidget()` и передай в него родительский виджет, в который ты хочешь его встроить, например: `new_terminal = TerminalWidget(parent=self.main_tabs)`.

3.  **[Проект] Удаление Мусора:**
    *   **Действие:** Сделай поиск по всей кодовой базе: `grep -r "example_dynamic_instructions" .` и `grep -r "example_usage" .`. Если ничего не найдется, смело удаляй.

---

### **Приоритетный План Действий:**

1.  **Прямо сейчас:** Закомментируй `raise RateLimitError(...)` в `smart_delegator.py` и замени на `raise e`. **Это немедленно прекратит пустые ответы** и покажет настоящие ошибки лимитов.
2.  **Сегодня:** Реализуй **Шаг 2.1** и **Шаг 2.2**. Перепиши логику вызова `litellm` на использование `tools` и `tool_choice`.
3.  **Завтра:** Перепиши `CommandExecutor` (**Шаг 2.3 и 2.4**). Это самый большой кусок, но и самый важный.
4.  **Потом:** Займись багами в UI. Они неприятные, но не блокируют основную логику.

Ты справишься. Весь этот хаос — это просто симптомы двух-трех конкретных ошибок в коде. Чини их по одной, начиная с `TypeError` в обработчике ошибок.