"""
Smart Workspace Indexer - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM.
–í–∫–ª—é—á–∞–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Ñ–∞–π–ª–æ–≤ —Å —É–º–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è,
–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–ê–≤—Ç–æ—Ä: GopiAI System
–í–µ—Ä—Å–∏—è: 1.0.0
"""

import os
import json
import time
import hashlib
import logging
from pathlib import Path
from typing import Dict, List, Optional, Set, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import fnmatch
import re

logger = logging.getLogger(__name__)

@dataclass
class ProjectInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ"""
    project_type: str
    primary_language: str
    technologies: List[str]
    frameworks: List[str]
    build_tools: List[str]
    package_managers: List[str]
    config_files: List[str]
    entry_points: List[str]
    test_directories: List[str]
    documentation_files: List[str]
    
@dataclass
class FileTreeNode:
    """–£–∑–µ–ª –¥–µ—Ä–µ–≤–∞ —Ñ–∞–π–ª–æ–≤"""
    name: str
    path: str
    is_directory: bool
    size: Optional[int] = None
    modified: Optional[float] = None
    children: Optional[List['FileTreeNode']] = None
    
@dataclass
class WorkspaceIndex:
    """–ü–æ–ª–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"""
    workspace_path: str
    project_info: ProjectInfo
    file_tree: FileTreeNode
    total_files: int
    total_size: int
    indexed_at: datetime
    cache_key: str

class ProjectTypeDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞
    PROJECT_PATTERNS = {
        'node': {
            'files': ['package.json', 'yarn.lock', 'package-lock.json'],
            'directories': ['node_modules'],
            'extensions': ['.js', '.ts', '.jsx', '.tsx']
        },
        'python': {
            'files': ['requirements.txt', 'setup.py', 'pyproject.toml', 'Pipfile', 'poetry.lock'],
            'directories': ['__pycache__', '.venv', 'venv', 'env'],
            'extensions': ['.py', '.pyx', '.pyi']
        },
        'java': {
            'files': ['pom.xml', 'build.gradle', 'gradle.properties'],
            'directories': ['src/main/java', 'target', 'build'],
            'extensions': ['.java', '.class', '.jar']
        },
        'csharp': {
            'files': ['*.csproj', '*.sln', 'packages.config'],
            'directories': ['bin', 'obj', 'packages'],
            'extensions': ['.cs', '.csx', '.vb']
        },
        'cpp': {
            'files': ['CMakeLists.txt', 'Makefile', 'configure.ac'],
            'directories': ['build', 'cmake-build-debug'],
            'extensions': ['.cpp', '.c', '.h', '.hpp', '.cc', '.cxx']
        },
        'rust': {
            'files': ['Cargo.toml', 'Cargo.lock'],
            'directories': ['target', 'src'],
            'extensions': ['.rs']
        },
        'go': {
            'files': ['go.mod', 'go.sum'],
            'directories': ['vendor'],
            'extensions': ['.go']
        },
        'php': {
            'files': ['composer.json', 'composer.lock'],
            'directories': ['vendor'],
            'extensions': ['.php', '.phtml']
        },
        'ruby': {
            'files': ['Gemfile', 'Gemfile.lock', '*.gemspec'],
            'directories': ['vendor/bundle'],
            'extensions': ['.rb', '.rake']
        },
        'swift': {
            'files': ['Package.swift', '*.xcodeproj', '*.xcworkspace'],
            'directories': ['.build'],
            'extensions': ['.swift']
        }
    }
    
    # –§—Ä–µ–π–º–≤–æ—Ä–∫–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
    FRAMEWORK_PATTERNS = {
        'react': ['package.json', 'react'],
        'vue': ['package.json', 'vue'],
        'angular': ['package.json', '@angular'],
        'django': ['requirements.txt', 'django', 'manage.py'],
        'flask': ['requirements.txt', 'flask'],
        'fastapi': ['requirements.txt', 'fastapi'],
        'spring': ['pom.xml', 'spring'],
        'express': ['package.json', 'express'],
        'nextjs': ['package.json', 'next'],
        'nuxt': ['package.json', 'nuxt'],
        'svelte': ['package.json', 'svelte'],
        'laravel': ['composer.json', 'laravel'],
        'rails': ['Gemfile', 'rails']
    }
    
    def detect_project_type(self, workspace_path: str) -> ProjectInfo:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        logger.info(f"[WORKSPACE-INDEXER] –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–æ–µ–∫—Ç–∞: {workspace_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–∞—Ö
        self.workspace_path = workspace_path
        
        # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
        root_files = self._get_root_files(workspace_path)
        all_files = self._get_all_files(workspace_path, max_depth=3)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞
        project_type = self._detect_primary_type(root_files, all_files)
        primary_language = self._detect_primary_language(all_files)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
        technologies = self._detect_technologies(root_files, all_files)
        frameworks = self._detect_frameworks(root_files, all_files)
        build_tools = self._detect_build_tools(root_files, workspace_path)
        package_managers = self._detect_package_managers(root_files)
        
        # –ù–∞—Ö–æ–¥–∏–º –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
        config_files = self._find_config_files(all_files)
        entry_points = self._find_entry_points(all_files, project_type)
        test_directories = self._find_test_directories(all_files)
        documentation_files = self._find_documentation_files(all_files)
        
        project_info = ProjectInfo(
            project_type=project_type,
            primary_language=primary_language,
            technologies=technologies,
            frameworks=frameworks,
            build_tools=build_tools,
            package_managers=package_managers,
            config_files=config_files,
            entry_points=entry_points,
            test_directories=test_directories,
            documentation_files=documentation_files
        )
        
        logger.info(f"[WORKSPACE-INDEXER] –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä–æ–µ–∫—Ç: {project_type} ({primary_language})")
        logger.info(f"[WORKSPACE-INDEXER] –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(technologies)}")
        logger.info(f"[WORKSPACE-INDEXER] –§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join(frameworks)}")
        
        return project_info
    
    def _get_root_files(self, workspace_path: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            return [f for f in os.listdir(workspace_path) 
                   if os.path.isfile(os.path.join(workspace_path, f))]
        except (OSError, PermissionError):
            return []
    
    def _get_all_files(self, workspace_path: str, max_depth: int = 3) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –≥–ª—É–±–∏–Ω—ã"""
        all_files = []
        try:
            for root, dirs, files in os.walk(workspace_path):
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É –ø–æ–∏—Å–∫–∞
                level = root.replace(workspace_path, '').count(os.sep)
                if level >= max_depth:
                    dirs[:] = []  # –ù–µ –∏–¥—ë–º –≥–ª—É–±–∂–µ
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in 
                          ['node_modules', '__pycache__', 'target', 'build', 'dist']]
                
                for file in files:
                    if not file.startswith('.'):
                        all_files.append(os.path.join(root, file))
        except (OSError, PermissionError):
            pass
        
        return all_files
    
    def _detect_primary_type(self, root_files: List[str], all_files: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞"""
        scores = {}
        
        for project_type, patterns in self.PROJECT_PATTERNS.items():
            score = 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ
            for pattern in patterns['files']:
                if any(fnmatch.fnmatch(f, pattern) for f in root_files):
                    score += 10
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            for ext in patterns['extensions']:
                count = sum(1 for f in all_files if f.endswith(ext))
                score += min(count, 5)  # –ú–∞–∫—Å–∏–º—É–º 5 –±–∞–ª–ª–æ–≤ –∑–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
            scores[project_type] = score
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏–ø —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å—á—ë—Ç–æ–º
        if scores:
            return max(scores, key=scores.get)
        return 'unknown'
    
    def _detect_primary_language(self, all_files: List[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"""
        language_counts = {}
        
        language_extensions = {
            'python': ['.py', '.pyx', '.pyi'],
            'javascript': ['.js', '.jsx', '.mjs'],
            'typescript': ['.ts', '.tsx'],
            'java': ['.java'],
            'csharp': ['.cs', '.csx'],
            'cpp': ['.cpp', '.c', '.cc', '.cxx'],
            'c': ['.c', '.h'],
            'rust': ['.rs'],
            'go': ['.go'],
            'php': ['.php', '.phtml'],
            'ruby': ['.rb', '.rake'],
            'swift': ['.swift'],
            'kotlin': ['.kt', '.kts'],
            'scala': ['.scala'],
            'html': ['.html', '.htm'],
            'css': ['.css', '.scss', '.sass', '.less'],
            'shell': ['.sh', '.bash', '.zsh']
        }
        
        for file_path in all_files:
            for language, extensions in language_extensions.items():
                if any(file_path.endswith(ext) for ext in extensions):
                    language_counts[language] = language_counts.get(language, 0) + 1
                    break
        
        if language_counts:
            return max(language_counts, key=language_counts.get)
        return 'unknown'
    
    def _detect_technologies(self, root_files: List[str], all_files: List[str]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"""
        technologies = set()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ñ–∞–π–ª–∞–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        tech_files = {
            'docker': ['Dockerfile', 'docker-compose.yml', '.dockerignore'],
            'kubernetes': ['*.yaml', '*.yml'],
            'terraform': ['*.tf', '*.tfvars'],
            'ansible': ['playbook.yml', 'ansible.cfg'],
            'webpack': ['webpack.config.js', 'webpack.config.ts'],
            'babel': ['.babelrc', 'babel.config.js'],
            'eslint': ['.eslintrc', '.eslintrc.js', '.eslintrc.json'],
            'prettier': ['.prettierrc', 'prettier.config.js'],
            'jest': ['jest.config.js', 'jest.config.json'],
            'pytest': ['pytest.ini', 'conftest.py'],
            'git': ['.gitignore', '.gitattributes'],
            'vscode': ['.vscode/'],
            'github-actions': ['.github/workflows/']
        }
        
        for tech, patterns in tech_files.items():
            for pattern in patterns:
                if any(fnmatch.fnmatch(f, pattern) for f in root_files):
                    technologies.add(tech)
                elif any(pattern in f for f in all_files):
                    technologies.add(tech)
        
        return list(technologies)
    
    def _detect_frameworks(self, root_files: List[str], all_files: List[str]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏"""
        frameworks = []
        
        # –ß–∏—Ç–∞–µ–º package.json –¥–ª—è Node.js –ø—Ä–æ–µ–∫—Ç–æ–≤
        if 'package.json' in root_files:
            frameworks.extend(self._detect_node_frameworks(root_files, self.workspace_path))
        
        # –ß–∏—Ç–∞–µ–º requirements.txt –¥–ª—è Python –ø—Ä–æ–µ–∫—Ç–æ–≤
        if any(f in root_files for f in ['requirements.txt', 'pyproject.toml']):
            frameworks.extend(self._detect_python_frameworks(root_files, self.workspace_path))
        
        return frameworks
    
    def _detect_node_frameworks(self, root_files: List[str], workspace_path: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç Node.js —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ –∏–∑ package.json"""
        frameworks = []
        
        if 'package.json' not in root_files:
            return frameworks
            
        try:
            package_json_path = os.path.join(workspace_path, 'package.json')
            
            with open(package_json_path, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
                
            dependencies = {**package_data.get('dependencies', {}), 
                          **package_data.get('devDependencies', {})}
            
            framework_mapping = {
                'react': 'React',
                'vue': 'Vue.js',
                '@angular/core': 'Angular',
                'express': 'Express.js',
                'next': 'Next.js',
                'nuxt': 'Nuxt.js',
                'svelte': 'Svelte',
                'gatsby': 'Gatsby',
                'electron': 'Electron'
            }
            
            for dep, framework in framework_mapping.items():
                if dep in dependencies:
                    frameworks.append(framework)
                    
        except (FileNotFoundError, json.JSONDecodeError, PermissionError):
            pass
            
        return frameworks
    
    def _detect_python_frameworks(self, root_files: List[str], workspace_path: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç Python —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ –∏–∑ requirements.txt"""
        frameworks = []
        
        framework_mapping = {
            'django': 'Django',
            'flask': 'Flask',
            'fastapi': 'FastAPI',
            'tornado': 'Tornado',
            'pyramid': 'Pyramid',
            'bottle': 'Bottle',
            'streamlit': 'Streamlit',
            'dash': 'Dash'
        }
        
        requirements_files = ['requirements.txt', 'requirements-dev.txt', 'requirements-prod.txt']
        
        for req_file in requirements_files:
            if req_file in root_files:
                try:
                    req_file_path = os.path.join(workspace_path, req_file)
                    with open(req_file_path, 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                        for package, framework in framework_mapping.items():
                            if package in content:
                                frameworks.append(framework)
                except (FileNotFoundError, PermissionError):
                    continue
        
        return frameworks
    
    def _detect_build_tools(self, root_files: List[str], workspace_path: str) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å–±–æ—Ä–∫–∏"""
        build_tools = []
        
        build_tool_mapping = {
            'webpack.config.js': 'Webpack',
            'rollup.config.js': 'Rollup',
            'vite.config.js': 'Vite',
            'gulpfile.js': 'Gulp',
            'Gruntfile.js': 'Grunt',
            'Makefile': 'Make',
            'CMakeLists.txt': 'CMake',
            'build.gradle': 'Gradle',
            'pom.xml': 'Maven',
            'Cargo.toml': 'Cargo',
            'setup.py': 'setuptools',
            'pyproject.toml': 'Poetry/setuptools'
        }
        
        for file, tool in build_tool_mapping.items():
            if file in root_files:
                build_tools.append(tool)
        
        return build_tools
    
    def _detect_package_managers(self, root_files: List[str]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä—ã –ø–∞–∫–µ—Ç–æ–≤"""
        package_managers = []
        
        manager_mapping = {
            'package-lock.json': 'npm',
            'yarn.lock': 'yarn',
            'pnpm-lock.yaml': 'pnpm',
            'requirements.txt': 'pip',
            'Pipfile': 'pipenv',
            'poetry.lock': 'poetry',
            'Gemfile': 'bundler',
            'composer.json': 'composer',
            'go.mod': 'go modules',
            'Cargo.lock': 'cargo'
        }
        
        for file, manager in manager_mapping.items():
            if file in root_files:
                package_managers.append(manager)
        
        return package_managers
    
    def _find_config_files(self, all_files: List[str]) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        config_patterns = [
            '*.config.js', '*.config.ts', '*.config.json',
            '.env*', '*.ini', '*.conf', '*.cfg',
            'tsconfig.json', 'jsconfig.json',
            '.babelrc*', '.eslintrc*', '.prettierrc*'
        ]
        
        config_files = []
        for file_path in all_files:
            file_name = os.path.basename(file_path)
            for pattern in config_patterns:
                if fnmatch.fnmatch(file_name, pattern):
                    config_files.append(file_path)
                    break
        
        return config_files[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    
    def _find_entry_points(self, all_files: List[str], project_type: str) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""
        entry_points = []
        
        entry_patterns = {
            'node': ['index.js', 'app.js', 'main.js', 'server.js', 'src/index.js'],
            'python': ['main.py', 'app.py', 'run.py', 'manage.py', '__main__.py'],
            'java': ['Main.java', 'Application.java'],
            'csharp': ['Program.cs', 'Main.cs'],
            'cpp': ['main.cpp', 'main.c'],
            'go': ['main.go'],
            'rust': ['main.rs', 'lib.rs']
        }
        
        patterns = entry_patterns.get(project_type, [])
        for file_path in all_files:
            file_name = os.path.basename(file_path)
            if file_name in patterns:
                entry_points.append(file_path)
        
        return entry_points
    
    def _find_test_directories(self, all_files: List[str]) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Ç–µ—Å—Ç–∞–º–∏"""
        test_dirs = set()
        test_patterns = ['test', 'tests', '__tests__', 'spec', 'specs']
        
        for file_path in all_files:
            path_parts = Path(file_path).parts
            for part in path_parts:
                if part.lower() in test_patterns:
                    test_dirs.add(str(Path(*path_parts[:path_parts.index(part)+1])))
        
        return list(test_dirs)
    
    def _find_documentation_files(self, all_files: List[str]) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        doc_patterns = [
            'README*', 'CHANGELOG*', 'LICENSE*', 'CONTRIBUTING*',
            'INSTALL*', 'USAGE*', 'API*', 'DOCS*',
            '*.md', '*.rst', '*.txt'
        ]
        
        doc_files = []
        for file_path in all_files:
            file_name = os.path.basename(file_path)
            for pattern in doc_patterns:
                if fnmatch.fnmatch(file_name.upper(), pattern.upper()):
                    doc_files.append(file_path)
                    break
        
        return doc_files[:15]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

class FileTreeBuilder:
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å –¥–µ—Ä–µ–≤–∞ —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π .gitignore"""
    
    def __init__(self):
        self.default_ignore_patterns = [
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
            '.DS_Store', 'Thumbs.db', 'desktop.ini',
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            '*.tmp', '*.temp', '*.swp', '*.swo', '*~',
            # –õ–æ–≥–∏
            '*.log', 'logs/', 'log/',
            # –ö—ç—à –∏ —Å–±–æ—Ä–∫–∞
            'node_modules/', '__pycache__/', '*.pyc', '*.pyo',
            'target/', 'build/', 'dist/', '.next/', '.nuxt/',
            'bin/', 'obj/', 'out/',
            # IDE —Ñ–∞–π–ª—ã
            '.vscode/', '.idea/', '*.suo', '*.user',
            # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            '.env', '.env.local', '.env.*.local',
            # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            'vendor/', 'packages/',
            # –î—Ä—É–≥–∏–µ
            '.git/', '.svn/', '.hg/'
        ]
    
    def build_file_tree(self, workspace_path: str) -> Tuple[FileTreeNode, int, int]:
        """–°—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤ —Å —É—á—ë—Ç–æ–º .gitignore"""
        logger.info(f"[WORKSPACE-INDEXER] –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Ñ–∞–π–ª–æ–≤: {workspace_path}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        ignore_patterns = self._load_ignore_patterns(workspace_path)
        
        # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ
        root_node = self._build_tree_recursive(workspace_path, ignore_patterns)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_files, total_size = self._calculate_stats(root_node)
        
        logger.info(f"[WORKSPACE-INDEXER] –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ –¥–µ—Ä–µ–≤–æ: {total_files} —Ñ–∞–π–ª–æ–≤, {total_size} –±–∞–π—Ç")
        
        return root_node, total_files, total_size
    
    def _load_ignore_patterns(self, workspace_path: str) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ .gitignore"""
        patterns = self.default_ignore_patterns.copy()
        
        gitignore_path = os.path.join(workspace_path, '.gitignore')
        if os.path.exists(gitignore_path):
            try:
                with open(gitignore_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            patterns.append(line)
                logger.info(f"[WORKSPACE-INDEXER] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
            except (OSError, UnicodeDecodeError):
                logger.warning("[WORKSPACE-INDEXER] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å .gitignore")
        
        return patterns
    
    def _should_ignore(self, path: str, patterns: List[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ–ª–∂–µ–Ω –ª–∏ –ø—É—Ç—å –±—ã—Ç—å –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω"""
        name = os.path.basename(path)
        
        for pattern in patterns:
            # –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if fnmatch.fnmatch(name, pattern):
                return True
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏
            if fnmatch.fnmatch(path, pattern):
                return True
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if pattern.endswith('/') and pattern[:-1] in path:
                return True
        
        return False
    
    def _build_tree_recursive(self, path: str, ignore_patterns: List[str], 
                            max_depth: int = 10, current_depth: int = 0) -> FileTreeNode:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤"""
        if current_depth > max_depth:
            return None
        
        name = os.path.basename(path) or path
        is_directory = os.path.isdir(path)
        
        try:
            stat = os.stat(path)
            size = stat.st_size if not is_directory else None
            modified = stat.st_mtime
        except (OSError, PermissionError):
            size = None
            modified = None
        
        node = FileTreeNode(
            name=name,
            path=path,
            is_directory=is_directory,
            size=size,
            modified=modified,
            children=[]
        )
        
        if is_directory:
            try:
                entries = os.listdir(path)
                entries.sort()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                
                for entry in entries:
                    entry_path = os.path.join(path, entry)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
                    if self._should_ignore(entry_path, ignore_patterns):
                        continue
                    
                    child_node = self._build_tree_recursive(
                        entry_path, ignore_patterns, max_depth, current_depth + 1
                    )
                    
                    if child_node:
                        node.children.append(child_node)
                        
            except (OSError, PermissionError):
                logger.warning(f"[WORKSPACE-INDEXER] –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {path}")
        
        return node
    
    def _calculate_stats(self, node: FileTreeNode) -> Tuple[int, int]:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –∏ —Ä–∞–∑–º–µ—Ä"""
        if not node:
            return 0, 0
        
        if not node.is_directory:
            return 1, node.size or 0
        
        total_files = 0
        total_size = 0
        
        if node.children:
            for child in node.children:
                files, size = self._calculate_stats(child)
                total_files += files
                total_size += size
        
        return total_files, total_size

class WorkspaceIndexerCache:
    """–°–∏—Å—Ç–µ–º–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
    
    def __init__(self, cache_dir: str = ".acf/cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_ttl = timedelta(minutes=5)  # 5 –º–∏–Ω—É—Ç TTL
    
    def _get_cache_key(self, workspace_path: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å –∏ –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –∫–ª—é—á–∞
        try:
            stat = os.stat(workspace_path)
            mtime = stat.st_mtime
            path_hash = hashlib.md5(workspace_path.encode()).hexdigest()
            return f"workspace_{path_hash}_{int(mtime)}"
        except OSError:
            return hashlib.md5(workspace_path.encode()).hexdigest()
    
    def get_cached_index(self, workspace_path: str) -> Optional[WorkspaceIndex]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –∏–∑ –∫—ç—à–∞"""
        cache_key = self._get_cache_key(workspace_path)
        cache_file = self.cache_dir / f"{cache_key}.json"
        
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            indexed_at = datetime.fromisoformat(data['indexed_at'])
            if datetime.now() - indexed_at > self.cache_ttl:
                logger.info("[WORKSPACE-INDEXER] –ö—ç—à —É—Å—Ç–∞—Ä–µ–ª, —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
                return None
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –∏–∑ JSON
            project_info = ProjectInfo(**data['project_info'])
            file_tree = self._deserialize_file_tree(data['file_tree'])
            
            workspace_index = WorkspaceIndex(
                workspace_path=data['workspace_path'],
                project_info=project_info,
                file_tree=file_tree,
                total_files=data['total_files'],
                total_size=data['total_size'],
                indexed_at=indexed_at,
                cache_key=cache_key
            )
            
            logger.info(f"[WORKSPACE-INDEXER] –ó–∞–≥—Ä—É–∂–µ–Ω –∏–Ω–¥–µ–∫—Å –∏–∑ –∫—ç—à–∞: {cache_key}")
            return workspace_index
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.warning(f"[WORKSPACE-INDEXER] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {e}")
            return None
    
    def save_index_to_cache(self, workspace_index: WorkspaceIndex) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω–¥–µ–∫—Å –≤ –∫—ç—à"""
        cache_file = self.cache_dir / f"{workspace_index.cache_key}.json"
        
        try:
            data = {
                'workspace_path': workspace_index.workspace_path,
                'project_info': asdict(workspace_index.project_info),
                'file_tree': self._serialize_file_tree(workspace_index.file_tree),
                'total_files': workspace_index.total_files,
                'total_size': workspace_index.total_size,
                'indexed_at': workspace_index.indexed_at.isoformat(),
                'cache_key': workspace_index.cache_key
            }
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"[WORKSPACE-INDEXER] –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∫—ç—à: {workspace_index.cache_key}")
            
        except (OSError, json.JSONEncodeError) as e:
            logger.error(f"[WORKSPACE-INDEXER] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")
    
    def _serialize_file_tree(self, node: FileTreeNode) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ JSON"""
        data = {
            'name': node.name,
            'path': node.path,
            'is_directory': node.is_directory,
            'size': node.size,
            'modified': node.modified
        }
        
        if node.children:
            data['children'] = [self._serialize_file_tree(child) for child in node.children]
        
        return data
    
    def _deserialize_file_tree(self, data: Dict) -> FileTreeNode:
        """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤ –∏–∑ JSON"""
        children = None
        if 'children' in data:
            children = [self._deserialize_file_tree(child) for child in data['children']]
        
        return FileTreeNode(
            name=data['name'],
            path=data['path'],
            is_directory=data['is_directory'],
            size=data.get('size'),
            modified=data.get('modified'),
            children=children
        )
    
    def clear_cache(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –≤–µ—Å—å –∫—ç—à"""
        try:
            for cache_file in self.cache_dir.glob("workspace_*.json"):
                cache_file.unlink()
            logger.info("[WORKSPACE-INDEXER] –ö—ç—à –æ—á–∏—â–µ–Ω")
        except OSError as e:
            logger.error(f"[WORKSPACE-INDEXER] –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")

class SmartWorkspaceIndexer:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"""
    
    def __init__(self, cache_dir: str = ".acf/cache"):
        self.project_detector = ProjectTypeDetector()
        self.file_tree_builder = FileTreeBuilder()
        self.cache = WorkspaceIndexerCache(cache_dir)
        
        logger.info("[WORKSPACE-INDEXER] Smart Workspace Indexer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def index_workspace(self, workspace_path: str, force_refresh: bool = False) -> WorkspaceIndex:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç —Ä–∞–±–æ—á–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
        
        Args:
            workspace_path: –ü—É—Ç—å –∫ —Ä–∞–±–æ—á–µ–º—É –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É
            force_refresh: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
            
        Returns:
            WorkspaceIndex: –ü–æ–ª–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        """
        logger.info(f"[WORKSPACE-INDEXER] –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {workspace_path}")
        start_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        if not force_refresh:
            cached_index = self.cache.get_cached_index(workspace_path)
            if cached_index:
                logger.info(f"[WORKSPACE-INDEXER] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å")
                return cached_index
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
        try:
            # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ–µ–∫—Ç–∞ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
            project_info = self.project_detector.detect_project_type(workspace_path)
            
            # 2. –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤
            file_tree, total_files, total_size = self.file_tree_builder.build_file_tree(workspace_path)
            
            # 3. –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å
            cache_key = self.cache._get_cache_key(workspace_path)
            workspace_index = WorkspaceIndex(
                workspace_path=workspace_path,
                project_info=project_info,
                file_tree=file_tree,
                total_files=total_files,
                total_size=total_size,
                indexed_at=datetime.now(),
                cache_key=cache_key
            )
            
            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.cache.save_index_to_cache(workspace_index)
            
            elapsed = time.time() - start_time
            logger.info(f"[WORKSPACE-INDEXER] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.2f}—Å")
            
            return workspace_index
            
        except Exception as e:
            logger.error(f"[WORKSPACE-INDEXER] –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            raise
    
    def get_project_summary(self, workspace_index: WorkspaceIndex) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è LLM"""
        project = workspace_index.project_info
        
        summary_parts = [
            f"–ü—Ä–æ–µ–∫—Ç: {project.project_type} ({project.primary_language})",
            f"–§–∞–π–ª–æ–≤: {workspace_index.total_files}",
            f"–†–∞–∑–º–µ—Ä: {self._format_size(workspace_index.total_size)}"
        ]
        
        if project.frameworks:
            summary_parts.append(f"–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join(project.frameworks)}")
        
        if project.technologies:
            summary_parts.append(f"–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {', '.join(project.technologies[:5])}")
        
        if project.build_tools:
            summary_parts.append(f"–°–±–æ—Ä–∫–∞: {', '.join(project.build_tools)}")
        
        return " | ".join(summary_parts)
    
    def get_file_tree_summary(self, workspace_index: WorkspaceIndex, max_depth: int = 3) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤"""
        def build_tree_text(node: FileTreeNode, depth: int = 0, max_depth: int = 3) -> List[str]:
            if depth > max_depth:
                return []
            
            lines = []
            indent = "  " * depth
            icon = "üìÅ" if node.is_directory else "üìÑ"
            
            lines.append(f"{indent}{icon} {node.name}")
            
            if node.children and depth < max_depth:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ
                for child in node.children[:10]:
                    lines.extend(build_tree_text(child, depth + 1, max_depth))
                
                if len(node.children) > 10:
                    lines.append(f"{indent}  ... –∏ –µ—â—ë {len(node.children) - 10} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            
            return lines
        
        tree_lines = build_tree_text(workspace_index.file_tree, max_depth=max_depth)
        return "\n".join(tree_lines[:50])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 50 —Å—Ç—Ä–æ–∫–∞–º–∏
    
    def get_context_for_llm(self, workspace_index: WorkspaceIndex) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è LLM"""
        context_parts = [
            "=== –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û–ï–ö–¢–ê ===",
            "",
            "üìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:",
            self.get_project_summary(workspace_index),
            "",
            "üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:",
            self.get_file_tree_summary(workspace_index),
            ""
        ]
        
        project = workspace_index.project_info
        
        if project.entry_points:
            context_parts.extend([
                "üöÄ –¢–û–ß–ö–ò –í–•–û–î–ê:",
                "\n".join(f"  ‚Ä¢ {ep}" for ep in project.entry_points[:5]),
                ""
            ])
        
        if project.config_files:
            context_parts.extend([
                "‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:",
                "\n".join(f"  ‚Ä¢ {cf}" for cf in project.config_files[:5]),
                ""
            ])
        
        if project.test_directories:
            context_parts.extend([
                "üß™ –¢–ï–°–¢–´:",
                "\n".join(f"  ‚Ä¢ {td}" for td in project.test_directories[:3]),
                ""
            ])
        
        context_parts.append("=== –ö–û–ù–ï–¶ –ö–û–ù–¢–ï–ö–°–¢–ê ===")
        
        return "\n".join(context_parts)
    
    def _format_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        for unit in ['–ë', '–ö–ë', '–ú–ë', '–ì–ë']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} –¢–ë"
    
    def clear_cache(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
        self.cache.clear_cache()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
_workspace_indexer = None

def get_workspace_indexer() -> SmartWorkspaceIndexer:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
    global _workspace_indexer
    if _workspace_indexer is None:
        _workspace_indexer = SmartWorkspaceIndexer()
    return _workspace_indexer

# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π
__all__ = [
    'SmartWorkspaceIndexer',
    'WorkspaceIndex',
    'ProjectInfo',
    'FileTreeNode',
    'get_workspace_indexer'
]